{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31716b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WKNN\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import operator\n",
    "\n",
    "# Define the data structure\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        xy = np.loadtxt(filepath,delimiter=',',dtype=np.float32)\n",
    "        self.len = xy.shape[0]\n",
    "        \n",
    "        # load the data after the second column of the dataset (RSS data)\n",
    "        self.x_data = torch.from_numpy(xy[:,2:])\n",
    "        # load the first two columns of the dataset (Coordinate)\n",
    "        self.y_data = torch.from_numpy(xy[:,0:2])\n",
    "        \n",
    "        #print(\"The data has prepared...\")\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Initialize the positioning error\n",
    "error_0 = []\n",
    "\n",
    "for z in range(1):\n",
    "    print(z)\n",
    "    # Settings\n",
    "    batch_size = 14\n",
    "    \n",
    "    # load traning and testing dataset\n",
    "    train_file = \"./dataset/03_14_train.csv\"\n",
    "    test_file = \"./dataset/03_10_test.csv\"\n",
    "    mydataset_train = MyDataset(train_file)\n",
    "    mydataset_test = MyDataset(test_file)\n",
    "    train_loader = DataLoader(dataset=mydataset_train,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                             num_workers=2)\n",
    "    test_loader = DataLoader(dataset=mydataset_test,\n",
    "                             batch_size=10,\n",
    "                             shuffle=True,\n",
    "                             num_workers=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Data preparing\n",
    "    for data, labels in train_loader:\n",
    "        train_data = data.view(-1, 64).numpy()\n",
    "        train_crd = labels.view(-1,2).numpy()\n",
    "        train_crd = 30*train_crd\n",
    "    for data, labels in test_loader:\n",
    "        test_data = data.view(-1, 64).numpy() \n",
    "        test_crd = labels.view(-1,2).numpy()\n",
    "        test_crd = 30*test_crd\n",
    "\n",
    "    # 1.Define the function to calculate the Euclidean distance\n",
    "    def euclideanDistance(instance1,instance2,length):\n",
    "        dis0 = 0\n",
    "        for i in range(0,length):\n",
    "            dis0 += (instance1[i]-instance2[i])**2\n",
    "        return dis0**0.5\n",
    "    \n",
    "    # 2.Select the K RPs with the shortest distance from the test point\n",
    "    def getNeighbors(trainSet,testPoint,k):\n",
    "        distance = []\n",
    "        length = len(testPoint)-2\n",
    "        for i in range(0,len(trainSet)):\n",
    "            dis1 = euclideanDistance(testPoint,trainSet[i],length)\n",
    "            distance.append((trainSet[i],dis1))\n",
    "        distance.sort(key = operator.itemgetter(1))      ## 对距离按照第二个域排序\n",
    "        neighbors = []\n",
    "        for j in range(0,k):\n",
    "            neighbors.append(distance[j])\n",
    "        return neighbors\n",
    "    \n",
    "    # 3.Calculate the weighted average of the K RP coordinates\n",
    "    def getResponse(neighbors):\n",
    "        add_weight = 0\n",
    "        crd = 0\n",
    "        for i in range(0,len(neighbors)):\n",
    "            add_weight += 1/neighbors[i][1] \n",
    "        for j in range(0,len(neighbors)):\n",
    "            crd += (neighbors[j][0][64:66]/neighbors[j][1])/add_weight\n",
    "        return crd\n",
    "    \n",
    "    # 4.Define the accuracy function\n",
    "    def getAccuracy(pred_crd,test_crd):\n",
    "        return np.mean(np.sqrt(np.sum((pred_crd-test_crd)**2,1)))\n",
    "    \n",
    "    # 5.main\n",
    "    train_file = np.hstack((train_data,train_crd))\n",
    "    test_file = np.hstack((test_data,test_crd))\n",
    "    k = 4\n",
    "    pred_crd = []\n",
    "    for i in range(0,len(test_file)):\n",
    "        neighbors = getNeighbors(train_file, test_file[i], k)\n",
    "        crd = getResponse(neighbors)\n",
    "        pred_crd.append(crd)\n",
    "    accuracy = getAccuracy(pred_crd,test_crd)\n",
    "    print(\"accuracy:\" + repr(accuracy) + \"m\")               ## print()内输出的内容格式必须一致\n",
    "    print(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),4))\n",
    "    \n",
    "    #error_0.append(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
