{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31716b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DeepPos\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the data structure\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        xy = np.loadtxt(filepath,delimiter=',',dtype=np.float32)\n",
    "        self.len = xy.shape[0]\n",
    "        \n",
    "        # load the data after the second column of the dataset (RSS data)\n",
    "        self.x_data = torch.from_numpy(xy[:,2:])\n",
    "        # load the first two columns of the dataset (Coordinate)\n",
    "        self.y_data = torch.from_numpy(xy[:,0:2])\n",
    "        \n",
    "        #print(\"The data has prepared...\")\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Initialize the positioning error\n",
    "error_0 = [[]for i in range(15)]\n",
    "\n",
    "realization = 500 # number of realizations\n",
    "for z in range(realization):\n",
    "    print(z)\n",
    "    # Settings\n",
    "    epochs = 1500\n",
    "    batch_size = 14\n",
    "    lr = 0.008\n",
    "    k=1\n",
    "    \n",
    "    # load traning and testing dataset\n",
    "    train_file = \"./dataset/03_14_train.csv\"\n",
    "    test_file = \"./dataset/03_10_test.csv\"\n",
    "    mydataset_train = MyDataset(train_file)\n",
    "    mydataset_test = MyDataset(test_file)\n",
    "    train_loader = DataLoader(dataset=mydataset_train,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=2)\n",
    "    test_loader = DataLoader(dataset=mydataset_test,\n",
    "                             batch_size=10,\n",
    "                             shuffle=False,\n",
    "                             num_workers=2)\n",
    "\n",
    "    # Model structure\n",
    "    class AutoEncoder(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(AutoEncoder, self).__init__()\n",
    "\n",
    "            # Encoder\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Linear(64, 48),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(48, 32),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(32, 2),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Linear(8, 4),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Linear(4, 2),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Linear(16, 2),\n",
    "            )\n",
    "            # Decoder\n",
    "            self.decoder = nn.Sequential(\n",
    "                #nn.Linear(2, 4),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Linear(4, 8),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Linear(8, 16),\n",
    "                #nn.Tanh(),\n",
    "                nn.Linear(16, 32),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(32, 48),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(48, 64),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "\n",
    "        def forward(self, inputs):\n",
    "            codes = self.encoder(inputs)\n",
    "            codes_new = torch.cat([codes, torch.eye(14)], 1) # Add label \n",
    "            decoded = self.decoder(codes_new)\n",
    "\n",
    "            return codes,decoded\n",
    "\n",
    "    #Loss Function\n",
    "    class My_loss(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, x, y):\n",
    "            return torch.mean(torch.sqrt((torch.pow((30*x - 30*y), 2)).sum(axis=-1)))\n",
    "            #return torch.mean((torch.pow((30*x - 30*y), 2)).sum(axis=1))\n",
    "\n",
    "    # Optimizer and loss function\n",
    "    model = AutoEncoder()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_function = nn.MSELoss()\n",
    "    loss_function_locate = My_loss()\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(epochs):\n",
    "        for data, labels in train_loader:\n",
    "            inputs = data.view(-1, 64) \n",
    "            locate = labels.view(-1,2)\n",
    "            # Forward\n",
    "            codes, decoded = model(inputs)\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            # Calculate loss\n",
    "            loss = loss_function(decoded, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        RP_train=locate\n",
    "        \n",
    "        #Test\n",
    "        if (epoch+1)%100 == 0 and epoch > 10:\n",
    "            print(epoch)\n",
    "            for data, labels in test_loader:\n",
    "                inputs = data.view(-1, 64) \n",
    "                locate = labels.view(-1,2)\n",
    "            RSS_test=inputs\n",
    "            RP_test=locate\n",
    "            loss_locate = 0\n",
    "            for i in range(10):\n",
    "                inputs_test=RSS_test[i].repeat(14,1)\n",
    "                codes, decoded = model(inputs_test)\n",
    "                loss_test=torch.mean((decoded-inputs_test)*(decoded-inputs_test),axis=1)\n",
    "                index=torch.argmin(loss_test)\n",
    "                loss_locate += loss_function_locate(RP_train[index],RP_test[i])\n",
    "            loss_locate=(loss_locate/10).numpy()\n",
    "            error_0[int((epoch+1)/100-1)].append(loss_locate)\n",
    "\n",
    "# Save the result            \n",
    "for i in range(15):\n",
    "    outcome_file = \"./outcome/SAE_\"+str(100+i*100)+\".csv\"  \n",
    "    error = [error_0[i]]\n",
    "    error = np.array(error)\n",
    "    data1 = pd.DataFrame(error.T)\n",
    "    data1.to_csv(outcome_file,header=None,index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
