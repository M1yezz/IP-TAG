{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31716b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using One-hot label\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the data structure\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        xy = np.loadtxt(filepath,delimiter=',',dtype=np.float32)\n",
    "        self.len = xy.shape[0]\n",
    "        \n",
    "        # load the data after the second column of the dataset (RSS data)\n",
    "        self.x_data = torch.from_numpy(xy[:,2:])\n",
    "        # load the first two columns of the dataset (Coordinate)\n",
    "        self.y_data = torch.from_numpy(xy[:,0:2])\n",
    "        \n",
    "        #print(\"The data has prepared...\")\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Initialize the positioning error\n",
    "error_0 = [[]for i in range(20)]\n",
    "error_1 = [[]for i in range(20)]\n",
    "error_2 = [[]for i in range(20)]\n",
    "error_3 = [[]for i in range(20)]\n",
    "error_4 = [[]for i in range(20)]\n",
    "error_5 = [[]for i in range(20)]\n",
    "\n",
    "realization = 500 # number of realizations\n",
    "for z in range(realization):\n",
    "    print(z)\n",
    "    # Settings\n",
    "    epochs = 200\n",
    "    batch_size = 14\n",
    "    lr = 0.008 #learning rate\n",
    "    k=1\n",
    "    \n",
    "    # load traning and testing dataset\n",
    "    train_file = \"./dataset/03_14_train.csv\"\n",
    "    test_file = \"./dataset/03_10_test.csv\"\n",
    "    mydataset_train = MyDataset(train_file)\n",
    "    mydataset_test = MyDataset(test_file)\n",
    "    train_loader = DataLoader(dataset=mydataset_train,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=2)\n",
    "    test_loader = DataLoader(dataset=mydataset_test,\n",
    "                             batch_size=10,\n",
    "                             shuffle=False,\n",
    "                             num_workers=2)\n",
    "\n",
    "    # Model structure\n",
    "    class AutoEncoder(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(AutoEncoder, self).__init__()\n",
    "\n",
    "            # Encoder\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Linear(64, 48),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(48, 32),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(32, 16),\n",
    "            )\n",
    "\n",
    "            # Decoder\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Linear(16, 32),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(32, 48),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(48, 64),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "        def forward(self, inputs):\n",
    "            codes = self.encoder(inputs)\n",
    "            decoded = self.decoder(codes)\n",
    "            return codes, decoded\n",
    "\n",
    "    # Loss Function\n",
    "    class My_loss(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, x, y):\n",
    "            return torch.mean(torch.sqrt((torch.pow((30*x - 30*y), 2)).sum(axis=1))) # Average positioning error\n",
    "\n",
    "    # Optimizer and loss function\n",
    "    model = AutoEncoder()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_function = nn.MSELoss()\n",
    "    loss_function_locate = My_loss()\n",
    "\n",
    "    # One-hot label setting\n",
    "    density = np.zeros((3,13))\n",
    "    density[1][6] = 1\n",
    "    density = torch.from_numpy(density)\n",
    "\n",
    "    # Add Label for training dataset\n",
    "    for data, labels in train_loader:\n",
    "        inputs = data.view(-1, 64) \n",
    "        locate = labels.view(-1,2)\n",
    "    r = torch.tensor([2,16])\n",
    "    j = torch.tensor([7,2])\n",
    "    l_c = torch.floor((30*locate-r)/j).int()\n",
    "    label_train = torch.ones((14,14))\n",
    "    for i in range(locate.size(0)):\n",
    "        label_train[i] = density[1-l_c[i][0]:3-l_c[i][0],6-l_c[i][1]:13-l_c[i][1]].flatten()\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(epochs):\n",
    "        for data, labels in train_loader:\n",
    "            inputs = data.view(-1, 64) \n",
    "            locate = labels.view(-1,2)\n",
    "            \n",
    "            # Forward\n",
    "            codes, decoded = model(inputs)\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_function(decoded, inputs) #the reconstruct error of AE\n",
    "            loss.backward()\n",
    "            optimizer.step()  \n",
    "            \n",
    "            for ep in range(10):\n",
    "                codes, decoded = model(inputs)\n",
    "                optimizer.zero_grad()\n",
    "                # loss function for coordinate and Label estimation\n",
    "                loss = loss_function_locate(codes[:,0:2], locate)+10*loss_function(codes[:,2:],label_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        # Show progress\n",
    "        locateloss = loss_function_locate(codes[:,0:2], locate)\n",
    "        labelloss = loss_function(codes[:,2:], label_train)\n",
    "        aeloss = loss_function(decoded, inputs)\n",
    "\n",
    "        # Test\n",
    "        if (epoch+1)%10 == 0 and epoch > 5:\n",
    "            print(epoch)\n",
    "            for data, labels in test_loader:\n",
    "                inputs = data.view(-1, 64) \n",
    "                locate = labels.view(-1,2)\n",
    "                codes, decoded = model(inputs)\n",
    "                label_class = codes[:,2:]\n",
    "                locate_test = codes[:,0:2]\n",
    "                e = loss_function_locate(locate,codes[:,0:2])\n",
    "            locate_0 = 30*codes[:,0:2] # estimated coordinates\n",
    "            locate_estim_1 = torch.ones((10,2))\n",
    "            locate_estim_2 = torch.ones((10,2))\n",
    "            locate_estim_3 = torch.ones((10,2))\n",
    "            locate_estim_4 = torch.ones((10,2))\n",
    "            locate_estim_5 = torch.ones((10,2))\n",
    "            \n",
    "            # Fix out-of-range locations for easy labeling\n",
    "            for i in range(locate.size(0)):\n",
    "                if locate_0[i][0]<2: locate_0[i][0] = 2\n",
    "                if locate_0[i][0]>=16: locate_0[i][0] = 16\n",
    "                if locate_0[i][1]<16: locate_0[i][1] = 16\n",
    "                if locate_0[i][1]>=30: locate_0[i][1] = 29.9\n",
    "\n",
    "            # Estimate the grid where the point is lying\n",
    "            label_test = torch.floor((locate_0-r)/j).int()\n",
    "\n",
    "            # Select the grid center coordinates corresponding to the largest k values in the Label\n",
    "            # Revise the estimated coordinates to obtain the revised coordinates\n",
    "            r_1 = torch.ones((1,2));r_2 = torch.ones((1,2));r_3 = torch.ones((1,2));r_4 = torch.ones((1,2));r_5 = torch.ones((1,2))\n",
    "            R_1 = torch.ones((1,2));R_2 = torch.ones((1,2));R_3 = torch.ones((1,2));R_4 = torch.ones((1,2));R_5 = torch.ones((1,2))\n",
    "            for i in range(label_class.size(0)):\n",
    "                index_0 = label_test[i][0]*7+label_test[i][1]\n",
    "                index_1 = torch.argmax(label_class[i],0)\n",
    "                r_1[0][0] = (index_1/7).int()\n",
    "                r_1[0][1] = index_1%7\n",
    "                R_1[0][0] = 5.5+7*r_1[0][0]\n",
    "                R_1[0][1] = 17+2*r_1[0][1]\n",
    "                label_class[i][index_1] = -1\n",
    "                index_2 = torch.argmax(label_class[i],0)\n",
    "                r_2[0][0] = (index_2/7).int()\n",
    "                r_2[0][1] = index_2%7\n",
    "                R_2[0][0] = 5.5+7*r_2[0][0]\n",
    "                R_2[0][1] = 17+2*r_2[0][1]\n",
    "                label_class[i][index_2] = -1\n",
    "                index_3 = torch.argmax(label_class[i],0)\n",
    "                r_3[0][0] = (index_3/7).int()\n",
    "                r_3[0][1] = index_3%7\n",
    "                R_3[0][0] = 5.5+7*r_3[0][0]\n",
    "                R_3[0][1] = 17+2*r_3[0][1]\n",
    "                label_class[i][index_3] = -1\n",
    "                index_4 = torch.argmax(label_class[i],0)\n",
    "                r_4[0][0] = (index_4/7).int()\n",
    "                r_4[0][1] = index_4%7\n",
    "                R_4[0][0] = 5.5+7*r_4[0][0]\n",
    "                R_4[0][1] = 17+2*r_4[0][1]\n",
    "                label_class[i][index_4] = -1\n",
    "                index_5 = torch.argmax(label_class[i],0)\n",
    "                r_5[0][0] = (index_5/7).int()\n",
    "                r_5[0][1] = index_5%7\n",
    "                R_5[0][0] = 5.5+7*r_5[0][0]\n",
    "                R_5[0][1] = 17+2*r_5[0][1]\n",
    "                R_one = R_1\n",
    "                R_two = (R_1+R_2)/2\n",
    "                R_three = (R_1+R_2+R_3)/3\n",
    "                R_four = (R_1+R_2+R_3+R_4)/4\n",
    "                R_five = (R_1+R_2+R_3+R_4+R_5)/5\n",
    "                # the revised coordinates\n",
    "                locate_estim_1[i] = (R_one+locate_0[i])/2\n",
    "                locate_estim_2[i] = (R_two+locate_0[i])/2\n",
    "                locate_estim_3[i] = (R_three+locate_0[i])/2\n",
    "                locate_estim_4[i] = (R_four+locate_0[i])/2\n",
    "                locate_estim_5[i] = (R_five+locate_0[i])/2\n",
    "            # Positioning error\n",
    "            error_0[int((epoch+1)/10-1)].append(loss_function_locate(locate,locate_0/30).detach().numpy())\n",
    "            error_1[int((epoch+1)/10-1)].append(loss_function_locate(locate,locate_estim_1/30).detach().numpy())\n",
    "            error_2[int((epoch+1)/10-1)].append(loss_function_locate(locate,locate_estim_2/30).detach().numpy())\n",
    "            error_3[int((epoch+1)/10-1)].append(loss_function_locate(locate,locate_estim_3/30).detach().numpy())\n",
    "            error_4[int((epoch+1)/10-1)].append(loss_function_locate(locate,locate_estim_4/30).detach().numpy())\n",
    "            error_5[int((epoch+1)/10-1)].append(loss_function_locate(locate,locate_estim_5/30).detach().numpy())\n",
    "\n",
    "# Save the result\n",
    "for i in range(20):\n",
    "    outcome_file = \"./outcome/our_model_update_110_01label_\"+str(10+i*10)+\".csv\"  \n",
    "    error = [error_0[i],error_1[i],error_2[i],error_3[i],error_4[i],error_5[i]]\n",
    "    error = np.array(error)\n",
    "    data1 = pd.DataFrame(error.T)\n",
    "    data1.to_csv(outcome_file,header=None,index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
